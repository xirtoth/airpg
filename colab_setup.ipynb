{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax33GbI4xXMB"
      },
      "source": [
        "# AI Fantasy RPG - Google Colab Setup (Updated: Feb 7, 2026 - Version 9)\n",
        "\n",
        "Run this notebook on Google Colab with GPU enabled for the best experience!\n",
        "\n",
        "**Setup Instructions:**\n",
        "1. Go to Runtime \u2192 Change runtime type \u2192 Select GPU (T4 recommended)\n",
        "2. Run all cells in order\n",
        "3. The game will launch in a web interface with a public URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35bQYcLjxXMD"
      },
      "source": [
        "## Step 1: Clone Repository and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HbLrxf6xXME",
        "outputId": "3186a7c9-f712-4e0b-a158-917d0cd47f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'airpg' already exists and is not an empty directory.\n",
            "/content/airpg\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone https://github.com/xirtoth/airpg.git\n",
        "%cd airpg\n",
        "\n",
        "# Alternative: Upload files manually if you prefer\n",
        "# Upload all .py files and requirements.txt to Colab manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U3Rm_SInxXMG",
        "outputId": "541246e6-c92c-40db-e4b3-f2640b3bdfc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u2705 Version 8 Installs done \u2014 NOW: Runtime \u2192 Restart runtime\n"
          ]
        }
      ],
      "source": [
        "# Forced dependency resolution fix (VERSION 9)\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q uninstall -y huggingface-hub transformers tokenizers datasets gradio numpy opencv-python opencv-python-headless opencv-contrib-python diffusers accelerate || true\n",
        "!pip -q install \\\n",
        "  \"numpy==2.0.2\" \\\n",
        "  \"huggingface-hub==0.33.5\" \\\n",
        "  \"transformers==4.44.0\" \\\n",
        "  \"tokenizers==0.19.1\" \\\n",
        "  \"datasets==2.13.0\" \\\n",
        "  \"gradio==5.7.1\" \\\n",
        "  \"diffusers==0.31.0\" \\\n",
        "  \"accelerate==0.33.0\" \\\n",
        "  \"opencv-python\" \\\n",
        "  \"opencv-python-headless\"\n",
        "\n",
        "print(\"\u2705 Version 9 Installs done \u2014 NOW: Runtime \u2192 Restart runtime\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rblwhrM-xXMH",
        "outputId": "0f07496c-0412-4415-f1df-fad4a5c55696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 2.0.2\n",
            "transformers: 4.41.0\n",
            "huggingface_hub: 0.33.5\n",
            "gradio: 5.50.0\n"
          ]
        }
      ],
      "source": [
        "# Step 1.1: Verify Versions (Run after Restart)\n",
        "import numpy, transformers, huggingface_hub, gradio\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
        "print(\"gradio:\", gradio.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSVN75rSxXMJ"
      },
      "source": [
        "## Step 2: Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xZ47OoGSxXMK",
        "outputId": "e6cafc83-7a10-4c7c-c752-5c0ce046f1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No GPU detected! Please enable GPU in Runtime \u2192 Change runtime type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n92ZCNDMxXML"
      },
      "source": [
        "## Step 3: Run the Game\n",
        "\n",
        "This will:\n",
        "1. Load upgraded AI models (Mistral 7B + SDXL-Turbo)\n",
        "2. Create a web interface\n",
        "3. Generate a public URL you can share\n",
        "\n",
        "**Note:** First run will take 5-10 minutes to download models (~10GB). Subsequent runs are much faster!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IsrjaGxGxXMM",
        "outputId": "b18b3426-24bc-4da8-818d-e4a9337506b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/airpg/game_ui_colab.py\", line 10, in <module>\n",
            "    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/__init__.py\", line 5, in <module>\n",
            "    from .utils import (\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/utils/__init__.py\", line 38, in <module>\n",
            "    from .dynamic_modules_utils import get_class_from_dynamic_module\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/utils/dynamic_modules_utils.py\", line 28, in <module>\n",
            "    from huggingface_hub import cached_download, hf_hub_download, model_info\n",
            "ImportError: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.12/dist-packages/huggingface_hub/__init__.py). Did you mean: 'hf_hub_download'?\n"
          ]
        }
      ],
      "source": [
        "# Launch the game!\n",
        "!python game_ui_colab.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}